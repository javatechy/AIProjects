{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94e053d5-7f31-4da7-90e4-7c6799468b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "is_debugging_enabled = False\n",
    "\n",
    "def debug_log(message):\n",
    "    if is_debugging_enabled:\n",
    "        print(f\"[DEBUG] {message}\")\n",
    "\n",
    "# Auto-convert date columns\n",
    "def auto_convert_dates(df):\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        except Exception as e:\n",
    "            print(f\"Could not convert {col}: {e}\")\n",
    "    return df\n",
    "    \n",
    "# Plot charts dynamically\n",
    "def plot_charts(spark_df):\n",
    "    \n",
    "    # Convert Spark DataFrame to Pandas\n",
    "    df = spark_df.toPandas()\n",
    "\n",
    "    print(\"\\n *************************************************************************************************************\")\n",
    "    # Display table\n",
    "    num_rows = 5\n",
    "    styled_df = df.head(min(num_rows, len(df))).style.set_table_attributes('style=\"width:40%\"').set_caption(\"Data in Raw Form\").hide(axis=\"index\")\n",
    "    display(styled_df)\n",
    "\n",
    "    if len(df) == 1 and len(df.columns) == 1:\n",
    "        # Handle single aggregation result\n",
    "        print(\"Aggregation result detected.\")\n",
    "        display(df)\n",
    "        return\n",
    "\n",
    "    # Automatically detect and convert date columns\n",
    "    df = auto_convert_dates(df)\n",
    "    print(\"\\n *************************************************************************************************************\")\n",
    "\n",
    "    # Detect date and numeric columns in Pandas DataFrame\n",
    "    date_cols = df.select_dtypes(include=['datetime', 'object']).columns\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Convert potential date columns\n",
    "    for col in date_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    # Filter valid datetime columns\n",
    "    date_cols = df.select_dtypes(include=['datetime']).columns\n",
    "    \n",
    "    if len(date_cols) == 0:\n",
    "        print(\"No datetime column detected, plotting using index.\")\n",
    "        df.reset_index(inplace=True)\n",
    "        date_col = df.index\n",
    "    else:\n",
    "        date_col = date_cols[0]  # Pick the first datetime column\n",
    "    \n",
    "    # Set axis limits\n",
    "    x_min = df[date_col].min()\n",
    "    x_max = df[date_col].max()\n",
    "\n",
    "    # Plot for each numeric column\n",
    "    for col in numeric_cols:\n",
    "        fig = px.line(df, x=date_col, y=col, title=f'{col} Over Time')\n",
    "        fig.update_layout(xaxis_range=[x_min, x_max])  # Fix axis to data range\n",
    "        fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "128b359a-91a0-4f4b-b1e2-a8eb022e32fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block : run_sql_command_on_spark\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"Block : run_sql_command_on_spark\")\n",
    "def run_sql_command_on_spark(sql_command):\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"DeltaTableReader\").master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    delta_table_path = \"E:/Downloads/yellow_tripdata_2024-07.parquet\"\n",
    "    df = spark.read.format(\"parquet\").load(delta_table_path)\n",
    "    df.createOrReplaceTempView(\"taxi_trips\")\n",
    "    if is_debugging_enabled:\n",
    "        print(\"checking the dataframe\")\n",
    "        df.show()\n",
    "    result = spark.sql(sql_command)\n",
    "    if is_debugging_enabled:\n",
    "        print(\"result after running the SQL command\")\n",
    "        result.show()\n",
    "    plot_charts(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b539c7f-fc5d-4601-aa65-1af440653111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block : call_llm\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import base64\n",
    "import json\n",
    "from openai import AzureOpenAI  \n",
    "\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://testaihubservice.openai.azure.com/\")  \n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o-mini\")  \n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://testaisearchservice830.search.windows.net/\")  \n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"--\")  \n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"--\")\n",
    "\n",
    "print(\"Block : call_llm\")\n",
    "\n",
    "def call_llm(user_input):\n",
    "    # Initialize Azure OpenAI client with key-based authentication    \n",
    "    client = AzureOpenAI(  \n",
    "        azure_endpoint=endpoint,  \n",
    "        api_key=subscription_key,  \n",
    "        api_version=\"2024-05-01-preview\",  \n",
    "    )\n",
    "    prompt_content = \"You are an AI assistant specialized in transforming natural language into SQL queries.The dataset includes embedding vectors representing predefined query patterns. Use these embeddings to adapt the generated SQL queries, aligning them with patterns found in the embedding dataset attached to the query. Return only the SQL output without explanations or comments\"    #Prepare the chat prompt \n",
    "    chat_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"{prompt_content}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{user_input}\"\n",
    "        }\n",
    "    ]\n",
    "        \n",
    "    # Include speech result if speech is enabled  \n",
    "    messages = chat_prompt  \n",
    "        \n",
    "    # Generate the completion  \n",
    "    completion = client.chat.completions.create(  \n",
    "        model=deployment,  \n",
    "        messages=messages,  \n",
    "        max_tokens=800,  \n",
    "        temperature=0.67,  \n",
    "        top_p=0.95,  \n",
    "        frequency_penalty=0,  \n",
    "        presence_penalty=0,  \n",
    "        stop=None,  \n",
    "        stream=False,\n",
    "        extra_body={\n",
    "          \"data_sources\": [{\n",
    "              \"type\": \"azure_search\",\n",
    "              \"parameters\": {\n",
    "                \"filter\": None,\n",
    "                \"endpoint\": f\"{search_endpoint}\",\n",
    "                 \"index_name\": \"dynamic-coat-vvlt360cf7\",\n",
    "                \"semantic_configuration\": \"azureml-default\",\n",
    "                \"authentication\": {\n",
    "                  \"type\": \"api_key\",\n",
    "                  \"key\": f\"{search_key}\"\n",
    "                },\n",
    "                \"embedding_dependency\": {\n",
    "                  \"type\": \"endpoint\",\n",
    "                  \"endpoint\": \"https://testaihubservice.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview\",\n",
    "                  \"authentication\": {\n",
    "                    \"type\": \"api_key\",\n",
    "                    \"key\": f\"{subscription_key}\"\n",
    "                  }\n",
    "                },\n",
    "                \"query_type\": \"vector_simple_hybrid\",\n",
    "                \"in_scope\": True,\n",
    "                \"role_information\": f\"{prompt_content}\",\n",
    "                \"strictness\": 3,\n",
    "                \"top_n_documents\": 5\n",
    "              }\n",
    "            }]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    res = completion.to_json()\n",
    "    if is_debugging_enabled:\n",
    "        print(\"res from LLM\"+ res)\n",
    "    res = json.loads(res)\n",
    "    content = res[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"Key response from LLM \" + content)\n",
    "\n",
    "    if \"SELECT\" in content:\n",
    "        # Remove ```sql and ``` from the content\n",
    "        clean_sql = content.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "        if is_debugging_enabled:\n",
    "            print(\"Cleaned up SQL command:\\n\" + clean_sql)\n",
    "        run_sql_command_on_spark(clean_sql)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "700ead4f-c495-4636-ab7c-2858c1ad08f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64aec54bc8cc4146b209ca46fd40535f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='50px', width='80%'), placeholder='Ask your question here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20467875803548f88cd86aa98264684d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Search', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e66dea7603a45e890f0ab303022075b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Text input widget\n",
    "text_input = widgets.Textarea(\n",
    "    placeholder='Ask your question here...',\n",
    "    layout=widgets.Layout(width='80%', height='50px')\n",
    ")\n",
    "\n",
    "# def call_llm(text):\n",
    "#     print(f\"I am text! Here's the input:\\n{text}\")\n",
    "        \n",
    "# Callback function to handle button click\n",
    "def button_callback(b):\n",
    "    with output:\n",
    "        clear_output()  # Clear previous output\n",
    "        text = text_input.value\n",
    "        #print(f\"I am clicked! Here's the input:\\n{text}\")\n",
    "        call_llm(text)\n",
    "        \n",
    "        \n",
    "# Button to trigger the action\n",
    "button = widgets.Button(description='Search')\n",
    "\n",
    "# Output widget to show results\n",
    "output = widgets.Output()\n",
    "\n",
    "# Attach the function to the button click event\n",
    "button.on_click(button_callback)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_input, button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27525d30-dec7-45cc-b0cf-98b4011c71e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
